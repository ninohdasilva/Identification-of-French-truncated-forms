{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31483b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n Authors Agostinho, Beji, Watiez\\nJune 2021 \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " Authors Agostinho, Beji, Watiez\n",
    "June 2021 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ea4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FICHIERS/DOSSIERS A TESTER:\n",
    "f = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960f5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NE PAS TOUCHER\n",
    "\n",
    "ROOT_CHAR = \"\"\n",
    "EMPTY_CHAR = \"\"\n",
    "MODELS_DIR = \"models/\"\n",
    "\n",
    "FILE_MODEL_EMBEDDINGS = \"model_embeddings_mc_taille-50-125-epochs.p\"\n",
    "FILE_TRIE = \"trie.p\"\n",
    "FILE_LEXICON = \"lexique.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1991f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modules à installer\n",
    "\n",
    "#!pip install nltk\n",
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12226f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnow\\.conda\\envs\\pytorch_p38\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "\n",
    "\n",
    "import nltk\n",
    "\"\"\"Bird, Steven, Edward Loper and Ewan Klein (2009),\n",
    " Natural Language Processing with Python. O’Reilly Media Inc.\n",
    "\"\"\"\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import pickle\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dcce74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trie:\n",
    "    \"\"\"\n",
    "    La classe Trie permet de stocker un dictionnaire sous forme d'arbre.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.rootNode = Node(ROOT_CHAR)\n",
    "    \n",
    "    def addWord(self, w):\n",
    "        temp_node = self.rootNode\n",
    "        for char in w:\n",
    "            temp_node = temp_node.addChild(char)\n",
    "        temp_node.setLeaf(True)\n",
    "            \n",
    "    def __str__(self):\n",
    "        return \"-->\".join(self.rootNode.wordsStartingFrom())\n",
    "    \n",
    "    def searchPrefix(self, w):\n",
    "        cur_node = self.rootNode\n",
    "        for char in w:\n",
    "            next_node = cur_node.getChild(char)\n",
    "            if next_node != None:\n",
    "                cur_node = next_node\n",
    "            else:\n",
    "                return None\n",
    "        return cur_node\n",
    "   \n",
    "    def searchWord(self, w):\n",
    "        node = self.searchPrefix(w)\n",
    "        return node != None and node.isLeaf()\n",
    "        \n",
    "    def fill(self, words_list):\n",
    "        for word in words_list:\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def inspect(self):\n",
    "        self.rootNode.inspect()\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Node est la classe des noeuds qui composent la Trie\n",
    "    \"\"\"\n",
    "    def __init__(self, c):\n",
    "        self.char = c\n",
    "        self.children = []\n",
    "        self.leaf = False\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.char\n",
    "        \n",
    "    def addChild(self, c):\n",
    "        existingChild = self.getChild(c)\n",
    "        if existingChild != None:\n",
    "            return existingChild \n",
    "        else:\n",
    "            new_node = Node(c)\n",
    "            self.children.append(new_node)\n",
    "            return new_node\n",
    "        \n",
    "    def getChildren(self):\n",
    "        return self.children\n",
    "    \n",
    "    def getChild(self, c):\n",
    "        for trie_node in self.children:\n",
    "            if trie_node.getChar() == c:\n",
    "                return trie_node\n",
    "        return None\n",
    "            \n",
    "    def getChar(self):\n",
    "        return self.char\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return self.leaf\n",
    "        \n",
    "    def setLeaf(self, b):\n",
    "        self.leaf = b\n",
    "\n",
    "    def wordsStartingFrom(self, prefix=\"\"):\n",
    "        words_list = []\n",
    "        if self.isLeaf():\n",
    "            words_list.append(EMPTY_CHAR) \n",
    "        for trie_node in self.children:\n",
    "            for s in trie_node.wordsStartingFrom():\n",
    "                words_list.append(prefix + trie_node.getChar() + s)\n",
    "        return words_list\n",
    "        \n",
    "    def inspect(self):\n",
    "        for c in self.getChildren():\n",
    "            c.inspect()\n",
    "        print(\"{} - {}\".format(self.char, self.leaf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af6cd249",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TroncWordsDetector:\n",
    "    \"\"\"\n",
    "    Classe Contenant les méthodes et objets permettant de chercher\n",
    "     des formes tronquées de mots dans un texte\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trie = Trie()\n",
    "        self.ready()\n",
    "        if FILE_MODEL_EMBEDDINGS not in os.listdir(MODELS_DIR):\n",
    "            print(\"Modèle d'Embeddings non trouvé: Chercher {}\".format(FILE_MODEL_EMBEDDINGS))\n",
    "            #sys.exit()\n",
    "        self.model_embeddings = pickle.load( open( MODELS_DIR + FILE_MODEL_EMBEDDINGS, \"rb\" ) )\n",
    "        self.nb_tronc_in_files = []\n",
    "        \n",
    "    def ready(self):\n",
    "        if FILE_TRIE in os.listdir(MODELS_DIR):\n",
    "            self.trie = pickle.load( open( MODELS_DIR + FILE_TRIE, \"rb\" ) )\n",
    "        else:\n",
    "            if FILE_LEXICON in os.listdir(MODELS_DIR):\n",
    "                with open(MODELS_DIR + FILE_LEXICON, encoding=\"utf-8\") as f:\n",
    "                    words_train = [line.rstrip() for line in f]\n",
    "                    print(len(words_train))\n",
    "                    for w in words_train:\n",
    "                        self.trie.addWord(w.lower())\n",
    "                pickle.dump( self.trie, open( MODELS_DIR + FILE_TRIE, \"wb\" ) )\n",
    "            else:\n",
    "                print(\"Aucun fichier de trie ou de lexique trouvé: chercher {} ou {}\".format(FILE_TRIE, FILE_LEXICON))\n",
    "                #sys.exit()\n",
    "        \n",
    "        \n",
    "    def run(self, f):\n",
    "        files_to_process = []\n",
    "        if os.path.isdir(f): \n",
    "            for filename in os.listdir(f):\n",
    "                files_to_process.append(os.path.join(f, filename))\n",
    "        else:\n",
    "            files_to_process.append(f)\n",
    "            \n",
    "        self.tok_and_lookForTronc(files_to_process)\n",
    "        \n",
    "    def tok_and_lookForTronc(self, files_to_process):\n",
    "        for filename in files_to_process:\n",
    "            tokenized_text = self.tokenize(filename)\n",
    "            self.lookForTroncWords(filename, tokenized_text)\n",
    "        print()\n",
    "        for filename, count in self.nb_tronc_in_files:\n",
    "            print(\"Fichier: {} - {} formes tronquées détectées\".format(filename, count))\n",
    "            \n",
    "    \"\"\"\n",
    "    @returns list of lists\n",
    "    \"\"\"\n",
    "    def tokenize(self, corpus_file):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokenized = []\n",
    "        f = open(corpus_file, encoding=\"utf-8\")\n",
    "        s = f.read()\n",
    "        f.close()\n",
    "        sents = nltk.sent_tokenize(s, language='french')\n",
    "        for sent in sents:\n",
    "            tokenized.append(tokenizer.tokenize(sent))\n",
    "        return tokenized\n",
    "\n",
    "    def should_process(self, word, id_word):\n",
    "        if len(word) < 2 or word.isupper() or (word[0].isupper() and id_word > 0):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def lookForTroncWords(self, filename, tokenized_text):\n",
    "        count = 0\n",
    "        nb_sents = len(tokenized_text)\n",
    "        for sent in tokenized_text:\n",
    "            for j in range(len(sent)):\n",
    "                word = sent[j]\n",
    "                if not self.should_process(word, j):\n",
    "                    continue\n",
    "                    \n",
    "                p = self.trie.searchPrefix(word.lower())\n",
    "                if  p != None and not p.isLeaf():\n",
    "                    possible_complete_forms = p.wordsStartingFrom(word)\n",
    "                    bis_possible_complete_forms = possible_complete_forms\n",
    "                    #----------\n",
    "                    for w in possible_complete_forms:\n",
    "                        #On vérifie si la possible forme complète a plus d'une lettre que la forme tronquée,\n",
    "                        # ce qui pourrait être une forme au féminin ou un pluriel\n",
    "                        if len(w) == len(word) + 1:  \n",
    "                            bis_possible_complete_forms.remove(w)\n",
    "                    if not len(bis_possible_complete_forms) == 0:\n",
    "                        if len(possible_complete_forms) > 1:\n",
    "                            most_probable_complete_form = self.check_complete_form(word, j, [w for w in sent])\n",
    "                        else:\n",
    "                            most_probable_complete_form = possible_complete_forms[0]\n",
    "                        print(\"[\" + word + \"/{}] :  (fichier: {})\".format(most_probable_complete_form, filename))\n",
    "                        count += 1\n",
    "        \n",
    "        self.nb_tronc_in_files.append((filename, count))\n",
    "        \n",
    "    def check_complete_form(self, word, index, sentence):\n",
    "        len_sent = len(sentence)\n",
    "        for i in range(len_sent):\n",
    "            if not i == index:\n",
    "                sentence[i] = sentence[i].lower()\n",
    "                if sentence[i].isnumeric():\n",
    "                    sentence[i] = \"*NUM*\"\n",
    "                elif not self.trie.searchWord(sentence[i]):\n",
    "                    sentence[i] = \"*UNK*\"\n",
    "        \n",
    "        \"\"\"win=2\"\"\"\n",
    "        index += 2\n",
    "        sentence = [\"*d1*\", \"*d2*\"] + sentence + [\"*f1*\", \"*f2*\"]\n",
    "        context = [sentence[index - 2], sentence[index - 1], sentence[index + 1], sentence[index + 2]]\n",
    "        \n",
    "        for w, p in self.model_embeddings.predict_output_word(context, topn=10000):\n",
    "            if w.startswith(word.lower()):\n",
    "                return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a8d1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rel/relativement] :  (fichier: test\\test.txt)\n",
      "[asp/aspects] :  (fichier: test\\test.txt)\n",
      "[app/application] :  (fichier: test\\test.txt)\n",
      "[dév/développement] :  (fichier: test\\test.txt)\n",
      "[syst/systématique] :  (fichier: test\\test.txt)\n",
      "[multi/multitude] :  (fichier: test\\test.txt)\n",
      "[indiv/individuels] :  (fichier: test\\test.txt)\n",
      "[allég/allégresse] :  (fichier: test\\test.txt)\n",
      "[proba/probable] :  (fichier: test\\test.txt)\n",
      "[incap/None] :  (fichier: test\\test.txt)\n",
      "[intér/intéressant] :  (fichier: test\\test.txt)\n",
      "[quot/quotidiennes] :  (fichier: test\\test.txt)\n",
      "[qual/qualité] :  (fichier: test\\test.txt)\n",
      "[espé/espérance] :  (fichier: test\\test.txt)\n",
      "[mod/mode] :  (fichier: test\\test.txt)\n",
      "[prob/problèmes] :  (fichier: test\\test.txt)\n",
      "[stat/station] :  (fichier: test\\test.txt)\n",
      "[propri/propriété] :  (fichier: test\\test.txt)\n",
      "[loc/localisées] :  (fichier: test\\test.txt)\n",
      "[diff/diffuser] :  (fichier: test\\test.txt)\n",
      "[prop/propriété] :  (fichier: test\\test.txt)\n",
      "[fréq/fréquente] :  (fichier: test\\test.txt)\n",
      "[sec/secondaires] :  (fichier: test\\test.txt)\n",
      "[croiss/croissance] :  (fichier: test\\test.txt)\n",
      "[prog/programmes] :  (fichier: test\\test.txt)\n",
      "[inscri/inscriptions] :  (fichier: test\\test.txt)\n",
      "[pos/possible] :  (fichier: test\\test.txt)\n",
      "[suff/suffisantes] :  (fichier: test\\test.txt)\n",
      "[prop/propriété] :  (fichier: test\\test.txt)\n",
      "[acqu/acquisition] :  (fichier: test\\test.txt)\n",
      "[lec/lecture] :  (fichier: test\\test.txt)\n",
      "[prob/problème] :  (fichier: test\\test.txt)\n",
      "[gén/générations] :  (fichier: test\\test.txt)\n",
      "[nat/nature] :  (fichier: test\\test.txt)\n",
      "[const/constater] :  (fichier: test\\test.txt)\n",
      "[indiv/individus] :  (fichier: test\\test.txt)\n",
      "[restau/restaurer] :  (fichier: test\\test.txt)\n",
      "[serv/services] :  (fichier: test\\test.txt)\n",
      "[moy/moyenne] :  (fichier: test\\test.txt)\n",
      "[imp/importante] :  (fichier: test\\test.txt)\n",
      "[comm/comme] :  (fichier: test\\test.txt)\n",
      "[comm/commerciales] :  (fichier: test\\test.txt)\n",
      "[asso/association] :  (fichier: test\\test.txt)\n",
      "[ret/retraite] :  (fichier: test\\test.txt)\n",
      "[ret/retraite] :  (fichier: test\\test.txt)\n",
      "[fact/facteurs] :  (fichier: test\\test.txt)\n",
      "[indiv/individualisme] :  (fichier: test\\test.txt)\n",
      "[press/pressé] :  (fichier: test\\test.txt)\n",
      "[trav/travail] :  (fichier: test\\test.txt)\n",
      "[rev/revenus] :  (fichier: test\\test.txt)\n",
      "[éco/écoles] :  (fichier: test\\test.txt)\n",
      "[pauv/pauvres] :  (fichier: test\\test.txt)\n",
      "[prop/proposé] :  (fichier: test\\test.txt)\n",
      "[disp/dispose] :  (fichier: test\\test.txt)\n",
      "[inf/inférieur] :  (fichier: test\\test.txt)\n",
      "[comparativ/comparativement] :  (fichier: test\\test.txt)\n",
      "[incap/incapacité] :  (fichier: test\\test.txt)\n",
      "[supp/suppression] :  (fichier: test\\test.txt)\n",
      "[bénéf/bénéfique] :  (fichier: test\\test.txt)\n",
      "[intér/intéressant] :  (fichier: test\\test.txt)\n",
      "[stat/stations] :  (fichier: test\\test.txt)\n",
      "[ret/retenue] :  (fichier: test\\test.txt)\n",
      "[suff/suffisante] :  (fichier: test\\test.txt)\n",
      "[imp/impossible] :  (fichier: test\\test.txt)\n",
      "[dist/distance] :  (fichier: test\\test.txt)\n",
      "[excl/exclusivement] :  (fichier: test\\test.txt)\n",
      "[pension/pensions] :  (fichier: test\\test.txt)\n",
      "[fourn/fournit] :  (fichier: test\\test.txt)\n",
      "[priv/privée] :  (fichier: test\\test.txt)\n",
      "[att/atteindre] :  (fichier: test\\test.txt)\n",
      "[remb/rembourser] :  (fichier: test\\test.txt)\n",
      "[tot/totalement] :  (fichier: test\\test.txt)\n",
      "[répart/répartition] :  (fichier: test\\test.txt)\n",
      "[ret/retirés] :  (fichier: test\\test.txt)\n",
      "[enr/enregistrés] :  (fichier: test\\test.txt)\n",
      "[inv/invités] :  (fichier: test\\test.txt)\n",
      "[hypo/hypothétiques] :  (fichier: test\\test.txt)\n",
      "[aut/autres] :  (fichier: test\\test.txt)\n",
      "[rev/revient] :  (fichier: test\\test.txt)\n",
      "[inf/informations] :  (fichier: test\\test.txt)\n",
      "[fai/fait] :  (fichier: test\\test.txt)\n",
      "[resp/respectivement] :  (fichier: test\\test.txt)\n",
      "[aff/affecté] :  (fichier: test\\test.txt)\n",
      "[act/activités] :  (fichier: test\\test.txt)\n",
      "[cont/contre] :  (fichier: test\\test.txt)\n",
      "[bénév/bénévoles] :  (fichier: test\\test.txt)\n",
      "[prév/prévenir] :  (fichier: test\\test.txt)\n",
      "[hyp/hypothèse] :  (fichier: test\\test.txt)\n",
      "[proj/projets] :  (fichier: test\\test.txt)\n",
      "[tot/totale] :  (fichier: test\\test.txt)\n",
      "[eff/effet] :  (fichier: test\\test.txt)\n",
      "[num/numérique] :  (fichier: test\\test.txt)\n",
      "[rés/résultats] :  (fichier: test\\test.txt)\n",
      "[rej/rejoindre] :  (fichier: test\\test.txt)\n",
      "[tech/techniques] :  (fichier: test\\test.txt)\n",
      "[hab/habituels] :  (fichier: test\\test.txt)\n",
      "[env/envers] :  (fichier: test\\test.txt)\n",
      "[fam/familles] :  (fichier: test\\test.txt)\n",
      "[aut/autres] :  (fichier: test\\test.txt)\n",
      "[indiv/individuelle] :  (fichier: test\\test.txt)\n",
      "[rep/représente] :  (fichier: test\\test.txt)\n",
      "[comp/compte] :  (fichier: test\\test.txt)\n",
      "[diff/difficile] :  (fichier: test\\test.txt)\n",
      "[auj/aujourd] :  (fichier: test\\test.txt)\n",
      "[bénéf/bénéficiez] :  (fichier: test\\test.txt)\n",
      "[meill/meilleure] :  (fichier: test\\test.txt)\n",
      "[esp/espèce] :  (fichier: test\\test.txt)\n",
      "[déb/début] :  (fichier: test\\test.txt)\n",
      "[nouv/nouvelles] :  (fichier: test\\test.txt)\n",
      "[év/éviter] :  (fichier: test\\test.txt)\n",
      "[org/organisation] :  (fichier: test\\test.txt)\n",
      "[intell/intelligente] :  (fichier: test\\test.txt)\n",
      "[pén/pénurie] :  (fichier: test\\test.txt)\n",
      "[adéq/adéquate] :  (fichier: test\\test.txt)\n",
      "[bes/besoins] :  (fichier: test\\test.txt)\n",
      "[rev/revenir] :  (fichier: test\\test.txt)\n",
      "[aug/augmentation] :  (fichier: test\\test.txt)\n",
      "[assist/assistance] :  (fichier: test\\test.txt)\n",
      "[maj/majorité] :  (fichier: test\\test.txt)\n",
      "[déf/défendre] :  (fichier: test\\test.txt)\n",
      "[phén/phénoménale] :  (fichier: test\\test.txt)\n",
      "[inf/informatique] :  (fichier: test\\test.txt)\n",
      "[comm/communication] :  (fichier: test\\test.txt)\n",
      "[ampl/None] :  (fichier: test\\test.txt)\n",
      "[chang/changement] :  (fichier: test\\test.txt)\n",
      "[techno/technologique] :  (fichier: test\\test.txt)\n",
      "[nouv/nouveaux] :  (fichier: test\\test.txt)\n",
      "[techni/techniques] :  (fichier: test\\test.txt)\n",
      "[automa/automatiquement] :  (fichier: test\\test.txt)\n",
      "[orga/organisation] :  (fichier: test\\test.txt)\n",
      "[ratta/rattachent] :  (fichier: test\\test.txt)\n",
      "[automat/automatisation] :  (fichier: test\\test.txt)\n",
      "[taylor/None] :  (fichier: test\\test.txt)\n",
      "[tens/tensions] :  (fichier: test\\test.txt)\n",
      "[rel/relatives] :  (fichier: test\\test.txt)\n",
      "[décou/découvertes] :  (fichier: test\\test.txt)\n",
      "[tech/techniques] :  (fichier: test\\test.txt)\n",
      "[décentr/décentralisation] :  (fichier: test\\test.txt)\n",
      "[dyna/dynamiques] :  (fichier: test\\test.txt)\n",
      "[organisat/organisation] :  (fichier: test\\test.txt)\n",
      "[cohé/cohérence] :  (fichier: test\\test.txt)\n",
      "[centr/centrale] :  (fichier: test\\test.txt)\n",
      "[jac/jacente] :  (fichier: test\\test.txt)\n",
      "[injustif/injustifiée] :  (fichier: test\\test.txt)\n",
      "[maîtr/maîtrise] :  (fichier: test\\test.txt)\n",
      "[fata/fatalité] :  (fichier: test\\test.txt)\n",
      "[croisi/croisière] :  (fichier: test\\test.txt)\n",
      "[facilit/facilité] :  (fichier: test\\test.txt)\n",
      "[quali/qualité] :  (fichier: test\\test.txt)\n",
      "[asp/aspects] :  (fichier: test\\test.txt)\n",
      "[consi/considérablement] :  (fichier: test\\test.txt)\n",
      "[strat/stratégie] :  (fichier: test\\test.txt)\n",
      "[glob/globale] :  (fichier: test\\test.txt)\n",
      "[intervention/interventions] :  (fichier: test\\test.txt)\n",
      "[compréhens/compréhension] :  (fichier: test\\test.txt)\n",
      "[ens/ensemble] :  (fichier: test\\test.txt)\n",
      "[intervention/interventions] :  (fichier: test\\test.txt)\n",
      "[effi/efficace] :  (fichier: test\\test.txt)\n",
      "[perspect/perspective] :  (fichier: test\\test.txt)\n",
      "[intervention/interventions] :  (fichier: test\\test.txt)\n",
      "[util/utilisateurs] :  (fichier: test\\test.txt)\n",
      "[éclai/éclairage] :  (fichier: test\\test.txt)\n",
      "[enj/enjeux] :  (fichier: test\\test.txt)\n",
      "[déter/déterminante] :  (fichier: test\\test.txt)\n",
      "[ajus/ajuster] :  (fichier: test\\test.txt)\n",
      "[fict/fiction] :  (fichier: test\\test.txt)\n",
      "[app/approprier] :  (fichier: test\\test.txt)\n",
      "[déter/déterminer] :  (fichier: test\\test.txt)\n",
      "[act/activités] :  (fichier: test\\test.txt)\n",
      "[conc/concerts] :  (fichier: test\\test.txt)\n",
      "[techno/technologie] :  (fichier: test\\test.txt)\n",
      "[impli/implicitement] :  (fichier: test\\test.txt)\n",
      "[desti/destinée] :  (fichier: test\\test.txt)\n",
      "[exis/existante] :  (fichier: test\\test.txt)\n",
      "[fortu/fortune] :  (fichier: test\\test.txt)\n",
      "[entrep/entreprise] :  (fichier: test\\test.txt)\n",
      "[bur/bureau] :  (fichier: test\\test.txt)\n",
      "[admi/administrative] :  (fichier: test\\test.txt)\n",
      "[graph/graphistes] :  (fichier: test\\test.txt)\n",
      "[perso/personnage] :  (fichier: test\\test.txt)\n",
      "[pig/pigeons] :  (fichier: test\\test.txt)\n",
      "[domi/domicile] :  (fichier: test\\test.txt)\n",
      "[perf/performance] :  (fichier: test\\test.txt)\n",
      "[quicon/quiconque] :  (fichier: test\\test.txt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[moti/motif] :  (fichier: test\\test.txt)\n",
      "[gam/gamme] :  (fichier: test\\test.txt)\n",
      "[invest/investissement] :  (fichier: test\\test.txt)\n",
      "[développé/développées] :  (fichier: test\\test.txt)\n",
      "[roul/roulement] :  (fichier: test\\test.txt)\n",
      "[compé/compétences] :  (fichier: test\\test.txt)\n",
      "[comm/comme] :  (fichier: test\\test.txt)\n",
      "[connaiss/connaissance] :  (fichier: test\\test.txt)\n",
      "[larg/largement] :  (fichier: test\\test.txt)\n",
      "[multidis/multidisciplinaire] :  (fichier: test\\test.txt)\n",
      "[relat/relation] :  (fichier: test\\test.txt)\n",
      "[clientè/clientèle] :  (fichier: test\\test.txt)\n",
      "[collab/collaborateurs] :  (fichier: test\\test.txt)\n",
      "[encadr/encadrement] :  (fichier: test\\test.txt)\n",
      "[solut/solutions] :  (fichier: test\\test.txt)\n",
      "[concu/concurrence] :  (fichier: test\\test.txt)\n",
      "[exploi/exploitation] :  (fichier: test\\test.txt)\n",
      "[astr/astres] :  (fichier: test\\test.txt)\n",
      "[régul/régulièrement] :  (fichier: test\\test.txt)\n",
      "[aff/affirme] :  (fichier: test\\test.txt)\n",
      "[questionn/questionnaire] :  (fichier: test\\test.txt)\n",
      "[cern/cerner] :  (fichier: test\\test.txt)\n",
      "[intervention/interventions] :  (fichier: test\\test.txt)\n",
      "[consac/consacré] :  (fichier: test\\test.txt)\n",
      "[tradu/traductions] :  (fichier: test\\test.txt)\n",
      "[docu/documents] :  (fichier: test\\test.txt)\n",
      "[famili/familiariser] :  (fichier: test\\test.txt)\n",
      "[nouv/nouveau] :  (fichier: test\\test.txt)\n",
      "[spéci/spécialiste] :  (fichier: test\\test.txt)\n",
      "[proc/proche] :  (fichier: test\\test.txt)\n",
      "[collabo/collaborations] :  (fichier: test\\test.txt)\n",
      "[diver/diversifiée] :  (fichier: test\\test.txt)\n",
      "[princip/principales] :  (fichier: test\\test.txt)\n",
      "[continuell/continuellement] :  (fichier: test\\test.txt)\n",
      "[infor/informatif] :  (fichier: test\\test.txt)\n",
      "[ag/agir] :  (fichier: test\\test.txt)\n",
      "[faisab/faisabilité] :  (fichier: test\\test.txt)\n",
      "[insta/installations] :  (fichier: test\\test.txt)\n",
      "[équip/équipes] :  (fichier: test\\test.txt)\n",
      "[repré/représentants] :  (fichier: test\\test.txt)\n",
      "[emp/employés] :  (fichier: test\\test.txt)\n",
      "[renco/rencontre] :  (fichier: test\\test.txt)\n",
      "[explo/explorer] :  (fichier: test\\test.txt)\n",
      "[trav/travail] :  (fichier: test\\test.txt)\n",
      "[électro/électronique] :  (fichier: test\\test.txt)\n",
      "[rech/recherche] :  (fichier: test\\test.txt)\n",
      "[intervention/interventions] :  (fichier: test\\test.txt)\n",
      "[conduit/conduites] :  (fichier: test\\test.txt)\n",
      "[procé/procédures] :  (fichier: test\\test.txt)\n",
      "[circon/circonstances] :  (fichier: test\\test.txt)\n",
      "[satisf/satisfait] :  (fichier: test\\test.txt)\n",
      "[déter/déterminer] :  (fichier: test\\test.txt)\n",
      "[spécif/spécifiquement] :  (fichier: test\\test.txt)\n",
      "[multidiscip/multidisciplinaire] :  (fichier: test\\test.txt)\n",
      "[vérific/None] :  (fichier: test\\test.txt)\n",
      "[orto/None] :  (fichier: test\\test.txt)\n",
      "[logi/logiciel] :  (fichier: test\\test.txt)\n",
      "[conju/conjugaison] :  (fichier: test\\test.txt)\n",
      "[développé/développées] :  (fichier: test\\test.txt)\n",
      "[permett/permettant] :  (fichier: test\\test.txt)\n",
      "[rédi/rédiger] :  (fichier: test\\test.txt)\n",
      "[termino/terminologies] :  (fichier: test\\test.txt)\n",
      "[accomp/accompagner] :  (fichier: test\\test.txt)\n",
      "[devr/devrait] :  (fichier: test\\test.txt)\n",
      "[itér/None] :  (fichier: test\\test.txt)\n",
      "[effect/effectuer] :  (fichier: test\\test.txt)\n",
      "[collabo/collaboration] :  (fichier: test\\test.txt)\n",
      "[prototy/prototypes] :  (fichier: test\\test.txt)\n",
      "[solu/solutions] :  (fichier: test\\test.txt)\n",
      "[expérim/expérimentation] :  (fichier: test\\test.txt)\n",
      "[éla/élaborer] :  (fichier: test\\test.txt)\n",
      "[ajus/ajustement] :  (fichier: test\\test.txt)\n",
      "[adap/adaptation] :  (fichier: test\\test.txt)\n",
      "[éval/évaluation] :  (fichier: test\\test.txt)\n",
      "[indiv/individuellement] :  (fichier: test\\test.txt)\n",
      "[dispo/dispositions] :  (fichier: test\\test.txt)\n",
      "[court/courte] :  (fichier: test\\test.txt)\n",
      "[questionn/questionnaire] :  (fichier: test\\test.txt)\n",
      "[encou/encouragés] :  (fichier: test\\test.txt)\n",
      "[amé/améliorer] :  (fichier: test\\test.txt)\n",
      "[prod/produits] :  (fichier: test\\test.txt)\n",
      "[démo/démonstrations] :  (fichier: test\\test.txt)\n",
      "[fourn/fournir] :  (fichier: test\\test.txt)\n",
      "[appr/apprendre] :  (fichier: test\\test.txt)\n",
      "[utili/utiliser] :  (fichier: test\\test.txt)\n",
      "[court/courts] :  (fichier: test\\test.txt)\n",
      "[incl/inclut] :  (fichier: test\\test.txt)\n",
      "[acc/accès] :  (fichier: test\\test.txt)\n",
      "[diss/dissous] :  (fichier: test\\test.txt)\n",
      "[rédact/rédacteurs] :  (fichier: test\\test.txt)\n",
      "[trad/traduit] :  (fichier: test\\test.txt)\n",
      "[identif/identification] :  (fichier: test\\test.txt)\n",
      "[trim/trimestre] :  (fichier: test\\test.txt)\n",
      "[effect/effectue] :  (fichier: test\\test.txt)\n",
      "[amélio/améliorer] :  (fichier: test\\test.txt)\n",
      "[satisf/satisfaction] :  (fichier: test\\test.txt)\n",
      "[cult/culture] :  (fichier: test\\test.txt)\n",
      "[collabo/collaborateurs] :  (fichier: test\\test.txt)\n",
      "[enrich/enrichir] :  (fichier: test\\test.txt)\n",
      "[élabo/élaborent] :  (fichier: test\\test.txt)\n",
      "[renouv/renouvellement] :  (fichier: test\\test.txt)\n",
      "[activ/activité] :  (fichier: test\\test.txt)\n",
      "[opp/opposition] :  (fichier: test\\test.txt)\n",
      "[caract/caractéristiques] :  (fichier: test\\test.txt)\n",
      "[log/logique] :  (fichier: test\\test.txt)\n",
      "[comman/commande] :  (fichier: test\\test.txt)\n",
      "[syst/système] :  (fichier: test\\test.txt)\n",
      "[restr/restreindre] :  (fichier: test\\test.txt)\n",
      "[circu/circulation] :  (fichier: test\\test.txt)\n",
      "[neut/neutralisé] :  (fichier: test\\test.txt)\n",
      "[rô/rôle] :  (fichier: test\\test.txt)\n",
      "[génér/génération] :  (fichier: test\\test.txt)\n",
      "[opér/opérations] :  (fichier: test\\test.txt)\n",
      "[deve/devenons] :  (fichier: test\\test.txt)\n",
      "[subj/subjectif] :  (fichier: test\\test.txt)\n",
      "[attit/attitudes] :  (fichier: test\\test.txt)\n",
      "[pension/None] :  (fichier: test\\test.txt)\n",
      "[retr/retraite] :  (fichier: test\\test.txt)\n",
      "[regr/regrets] :  (fichier: test\\test.txt)\n",
      "[regr/regroupement] :  (fichier: test\\test.txt)\n",
      "[champ/championnat] :  (fichier: test\\test.txt)\n",
      "[remarq/remarquer] :  (fichier: test\\test.txt)\n",
      "[ressor/ressortir] :  (fichier: test\\test.txt)\n",
      "[propor/proportion] :  (fichier: test\\test.txt)\n",
      "[considé/considérablement] :  (fichier: test\\test.txt)\n",
      "[eth/ethniques] :  (fichier: test\\test.txt)\n",
      "[espé/espérance] :  (fichier: test\\test.txt)\n",
      "[naiss/naissance] :  (fichier: test\\test.txt)\n",
      "[excell/excellent] :  (fichier: test\\test.txt)\n",
      "[favo/favorise] :  (fichier: test\\test.txt)\n",
      "[démog/démographiques] :  (fichier: test\\test.txt)\n",
      "[vieilliss/vieillissement] :  (fichier: test\\test.txt)\n",
      "[handic/handicap] :  (fichier: test\\test.txt)\n",
      "[irrév/irréversibles] :  (fichier: test\\test.txt)\n",
      "[géront/gérontologie] :  (fichier: test\\test.txt)\n",
      "[gériat/None] :  (fichier: test\\test.txt)\n",
      "[incap/incapable] :  (fichier: test\\test.txt)\n",
      "[défici/déficits] :  (fichier: test\\test.txt)\n",
      "[milli/millions] :  (fichier: test\\test.txt)\n",
      "[comparat/comparativement] :  (fichier: test\\test.txt)\n",
      "[démen/None] :  (fichier: test\\test.txt)\n",
      "[ménage/ménages] :  (fichier: test\\test.txt)\n",
      "[locat/location] :  (fichier: test\\test.txt)\n",
      "[scol/scolaire] :  (fichier: test\\test.txt)\n",
      "[seco/secondaires] :  (fichier: test\\test.txt)\n",
      "[croiss/croissance] :  (fichier: test\\test.txt)\n",
      "[éduc/éducateurs] :  (fichier: test\\test.txt)\n",
      "\n",
      "Fichier: test\\test.txt - 331 formes tronquées détectées\n",
      "Exécution terminée en - 36.70283079147339 secondes -\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "detector = TroncWordsDetector()\n",
    "detector.run(f)\n",
    "print(\"Exécution terminée en - %s secondes -\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ef81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
